# Guidelines for ETL Project

This document contains guidelines, requirements, and suggestions for Project 1.

## Team Effort

Due to the short timeline, teamwork will be crucial to the success of this project! Work closely with your team through all phases of the project to ensure that there are no surprises at the end of the week.

Working in a group enables you to tackle more difficult problems than you'd be able to working alone. In other words, working in a group allows you to **work smart** and **dream big**. Take advantage of it!

## Project Proposal

Before you start writing any code, remember that you only have one week to complete this project. View this project as a typical assignment from work. Imagine a bunch of data came in and you and your team are tasked with migrating it to a production data base.

Take advantage of your Instructor and TA support during office hours and class project work time. They are a valuable resource and can help you stay on track.

## Finding Data

Your project must use 2 or more sources of data. We recommend the following sites to use as sources of data:

* [data.world](https://data.world/)

* [Kaggle](https://www.kaggle.com/)

You can also use APIs or data scraped from the web. However, get approval from your instructor first. Again, there is only a week to complete this!

## Data Cleanup & Analysis

Once you have identified your datasets, perform ETL on the data. Make sure to plan and document the following:

* The sources of data that you will extract from.

The sources are:
- "http://www.uscampgrounds.info/". I queried the web API and return the message with access denied. The script ran with 200 response but error with access denied. 
I tried to  debug the code however wasn't successful so i downloaded the CSV file data that were available in the site for year 2018.
- "https://www.tripadvisor.com/Hotels-g61000-c3-zff29-Yosemite_National_Park_California-Hotels.html"I used Tripadvisor website to scrape the data on the yesomite National Park. 
then converted it into pandas data frame to export out to csv file.
	 

* The type of transformation needed for this data (cleaning, joining, filtering, aggregating, etc).
- uscampgroundsinfo had 57 column with some blank row. I loaded the file into python and clean it to 11 columns with new dataframe and exported it to CSV file 

- I scraped the tripadvisor website limiting the search to Yesomite National Park and extracted three fields-Title,Total_Reviews,comments into pandas dataframe and exported it into csv file.

* The type of final production database to load the data into (relational or non-relational).
- I created relational databases  with these two CSV files .

* The final tables or collections that will be used in the production database.
-Reservation_campground database with two tables camp_reservation and campground_comment. camp_reservation can be linked on Park_name from camp_comments.


You will be required to submit a final technical report with the above information and steps required to reproduce your ETL process.

## Project Report

At the end of the week, your team will submit a Final Report that describes the following:

* **E**xtract: your original data sources and how the data was formatted (CSV, JSON, pgAdmin 4, etc).
- data was extracted into csv file from python 

* **T**ransform: what data cleaning or transformation was required.
selective columns are selected and transformed into dataframe to match columns from other table

* **L**oad: the final database, tables/collections, and why this was chosen.
Loaded file into PgAdmin for each dataset so the each campground reviews and comments can be sort out. 

Please upload the report to Github and submit a link to Bootcampspot.

- - -

### Copyright

Coding Boot Camp © 2019. All Rights Reserved.
